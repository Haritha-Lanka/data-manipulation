{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1894ccac",
   "metadata": {},
   "source": [
    "# Data Manipulation Studio\n",
    "\n",
    "For this studio, we will revisit our California farmers looking for advice on growing pumpkins and the same [pumpkins dataset](https://www.kaggle.com/usda/a-year-of-pumpkin-prices) as provided by the U.S. Department of Agriculture. You may have to clean data in the process of data manipulation, so feel free to pull up your notebook from the last class's studio.\n",
    "\n",
    "We will now be focusing our attention on a different region in the United States, the Northeast. When you open up the `dataset` folder, you will have 13 CSVs, including the San Francisco and Los Angeles data from the last lesson. The 13 CSVs are each a different terminal market in the United States.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Import the CSVs for each of the following cities: Baltimore, Boston, New York, and Philadelphia. Set up a dataframe for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66c9a7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153, 25)\n",
      "(352, 25)\n",
      "(112, 25)\n",
      "(57, 25)\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries and CSVs. Make some dataframes!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_Baltimore= pd.read_csv(\"baltimore_9-24-2016_9-30-2017.csv\")\n",
    "df_Boston=pd.read_csv(\"boston_9-24-2016_9-30-2017.csv\")\n",
    "df_NewYork=pd.read_csv(\"new-york_9-24-2016_9-30-2017.csv\")\n",
    "df_Philadelphia=pd.read_csv(\"philadelphia_9-24-2016_9-30-2017.csv\")\n",
    "print(df_Baltimore.shape)\n",
    "print(df_Boston.shape)\n",
    "print(df_NewYork.shape)\n",
    "print(df_Philadelphia.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfda42f",
   "metadata": {},
   "source": [
    "## Clean Your Data\n",
    "\n",
    "In the last lesson, we cleaned the data to related to San Francisco. Pull up your notebook from the last lesson and use your cleaning skills to clean the dataframes as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98abc290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 1%\n",
      "Sub Variety - 84%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 3%\n",
      "Origin District - 100%\n",
      "Item Size - 16%\n",
      "Color - 80%\n",
      "Environment - 100%\n",
      "Unit of Sale - 84%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "# Clean your data here!\n",
    "#find missing data percentage in df_Baltimore\n",
    "for col in df_Baltimore.columns:\n",
    "    pct_missing = np.mean(df_Baltimore[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab29148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 0%\n",
      "Sub Variety - 92%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 0%\n",
      "Origin District - 81%\n",
      "Item Size - 1%\n",
      "Color - 14%\n",
      "Environment - 100%\n",
      "Unit of Sale - 87%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "#find missing data percentage in df_Boston\n",
    "for col in df_Boston.columns:\n",
    "    pct_missing = np.mean(df_Boston[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f29f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 0%\n",
      "Sub Variety - 84%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 0%\n",
      "Origin District - 87%\n",
      "Item Size - 7%\n",
      "Color - 81%\n",
      "Environment - 100%\n",
      "Unit of Sale - 78%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "#find missing data percentage in df_NewYork\n",
    "for col in df_NewYork.columns:\n",
    "    pct_missing = np.mean(df_NewYork[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00552b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 0%\n",
      "Sub Variety - 79%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 0%\n",
      "Origin District - 100%\n",
      "Item Size - 21%\n",
      "Color - 100%\n",
      "Environment - 100%\n",
      "Unit of Sale - 81%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "#find missing data percentage in df_Philadelphia\n",
    "for col in df_Philadelphia.columns:\n",
    "    pct_missing = np.mean(df_Philadelphia[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e718fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the Missing Values in the Type Column with \"Conventional\" for all dataframes\n",
    "df_Baltimore[\"Type\"] = df_Baltimore[\"Type\"].fillna(\"Conventional\")\n",
    "df_Boston[\"Type\"] = df_Boston[\"Type\"].fillna(\"Conventional\")\n",
    "df_NewYork[\"Type\"] = df_NewYork[\"Type\"].fillna(\"Conventional\")\n",
    "df_Philadelphia[\"Type\"] = df_Philadelphia[\"Type\"].fillna(\"Conventional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7497e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the 'Grade' column in all the data frames\n",
    "df_Baltimore = df_Baltimore.drop([\"Grade\"], axis=1) \n",
    "df_Boston = df_Boston.drop([\"Grade\"], axis=1) \n",
    "df_NewYork = df_NewYork.drop([\"Grade\"], axis=1) \n",
    "df_Philadelphia =df_Philadelphia.drop([\"Grade\"], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ada349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment - can be dropped as it is additional notes\n",
    "# Unit of Sale - can be dropped as it is additional notes\n",
    "# Quality - can be dropped as it is additional notes\n",
    "# Condition - can be dropped as it is additional notes\n",
    "# Appearance - can be dropped as it is additional notes\n",
    "# Storage - can be dropped as it is additional notes\n",
    "# Crop - can be dropped as it is additional notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da1ce265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Baltimore = df_Baltimore.drop([\"Environment\"], axis=1)\n",
    "df_Baltimore = df_Baltimore.drop([\"Unit of Sale\"], axis=1)\n",
    "df_Baltimore = df_Baltimore.drop([\"Quality\"], axis=1)\n",
    "df_Baltimore = df_Baltimore.drop([\"Condition\"], axis=1)\n",
    "df_Baltimore = df_Baltimore.drop([\"Appearance\"], axis=1)\n",
    "df_Baltimore = df_Baltimore.drop([\"Storage\"], axis=1)\n",
    "df_Baltimore = df_Baltimore.drop([\"Crop\"], axis=1)\n",
    "df_Boston = df_Boston.drop([\"Environment\"], axis=1)\n",
    "df_Boston = df_Boston.drop([\"Unit of Sale\"], axis=1)\n",
    "df_Boston = df_Boston.drop([\"Quality\"], axis=1)\n",
    "df_Boston = df_Boston.drop([\"Condition\"], axis=1)\n",
    "df_Boston = df_Boston.drop([\"Appearance\"], axis=1)\n",
    "df_Boston = df_Boston.drop([\"Storage\"], axis=1)\n",
    "df_Boston = df_Boston.drop([\"Crop\"], axis=1)\n",
    "df_NewYork = df_NewYork.drop([\"Environment\"], axis=1)\n",
    "df_NewYork = df_NewYork.drop([\"Unit of Sale\"], axis=1)\n",
    "df_NewYork = df_NewYork.drop([\"Quality\"], axis=1)\n",
    "df_NewYork = df_NewYork.drop([\"Condition\"], axis=1)\n",
    "df_NewYork = df_NewYork.drop([\"Appearance\"], axis=1)\n",
    "df_NewYork = df_NewYork.drop([\"Storage\"], axis=1)\n",
    "df_NewYork = df_NewYork.drop([\"Crop\"], axis=1)\n",
    "df_Philadelphia = df_Philadelphia.drop([\"Environment\"], axis=1)\n",
    "df_Philadelphia = df_Philadelphia.drop([\"Unit of Sale\"], axis=1)\n",
    "df_Philadelphia = df_Philadelphia.drop([\"Quality\"], axis=1)\n",
    "df_Philadelphia = df_Philadelphia.drop([\"Condition\"], axis=1)\n",
    "df_Philadelphia = df_Philadelphia.drop([\"Appearance\"], axis=1)\n",
    "df_Philadelphia = df_Philadelphia.drop([\"Storage\"], axis=1)\n",
    "df_Philadelphia = df_Philadelphia.drop([\"Crop\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57f41df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Origin District can be dropped because we have Origin column which is sufficient data\n",
    "df_Baltimore = df_Baltimore.drop([\"Origin District\"], axis=1)\n",
    "df_Boston = df_Boston.drop([\"Origin District\"], axis=1)\n",
    "df_NewYork = df_NewYork.drop([\"Origin District\"], axis=1)\n",
    "df_Philadelphia = df_Philadelphia.drop([\"Origin District\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68e8e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trans Mode - can be dropped as it does not have any data\n",
    "df_Baltimore = df_Baltimore.drop([\"Trans Mode\"], axis=1)\n",
    "df_Boston = df_Boston.drop([\"Trans Mode\"], axis=1)\n",
    "df_NewYork = df_NewYork.drop([\"Trans Mode\"], axis=1)\n",
    "df_Philadelphia = df_Philadelphia.drop([\"Trans Mode\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86fa1b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub Variety - can be dropped as it has  missing data\n",
    "df_Baltimore = df_Baltimore.drop([\"Sub Variety\"], axis=1)\n",
    "df_Boston = df_Boston.drop([\"Sub Variety\"], axis=1)\n",
    "df_NewYork = df_NewYork.drop([\"Sub Variety\"], axis=1)\n",
    "df_Philadelphia = df_Philadelphia.drop([\"Sub Variety\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eb3f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color - can be dropped as it has  missing data\n",
    "df_Baltimore = df_Baltimore.drop([\"Color\"], axis=1)\n",
    "df_Boston = df_Boston.drop([\"Color\"], axis=1)\n",
    "df_NewYork = df_NewYork.drop([\"Color\"], axis=1)\n",
    "df_Philadelphia = df_Philadelphia.drop([\"Color\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66fefd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item Size - can be dropped as it has  missing data\n",
    "df_Baltimore = df_Baltimore.drop([\"Item Size\"], axis=1)\n",
    "df_Boston = df_Boston.drop([\"Item Size\"], axis=1)\n",
    "df_NewYork = df_NewYork.drop([\"Item Size\"], axis=1)\n",
    "df_Philadelphia = df_Philadelphia.drop([\"Item Size\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d631f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicates from all the dataframes\n",
    "df_Baltimore = df_Baltimore.drop_duplicates()\n",
    "df_Boston = df_Boston.drop_duplicates()\n",
    "df_NewYork = df_NewYork.drop_duplicates()\n",
    "df_Philadelphia = df_Philadelphia.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba58dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the rows with missing values in df_Baltimore under columns \"Variety\" and \"Origin\"\n",
    "df_Baltimore=df_Baltimore.dropna(subset=['Variety','Origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef47a82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135, 12)\n",
      "(285, 12)\n",
      "(102, 12)\n",
      "(54, 12)\n"
     ]
    }
   ],
   "source": [
    "#check the shape of the data frames \n",
    "print(df_Baltimore.shape)\n",
    "print(df_Boston.shape)\n",
    "print(df_NewYork.shape)\n",
    "print(df_Philadelphia.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b01b9",
   "metadata": {},
   "source": [
    "## Combine Your Data\n",
    "\n",
    "Now that you have four clean sets of data, combine all four into one dataframe that represents the entire Northeast region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da059f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the four dataframes into one!\n",
    "frames=[df_Baltimore,df_Boston,df_NewYork,df_Philadelphia]\n",
    "df=pd.concat(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e2013c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 12)\n",
      "Index(['Commodity Name', 'City Name', 'Type', 'Package', 'Variety', 'Date',\n",
      "       'Low Price', 'High Price', 'Mostly Low', 'Mostly High', 'Origin',\n",
      "       'Repack'],\n",
      "      dtype='object')\n",
      "  Commodity Name  City Name          Type       Package      Variety  \\\n",
      "2       PUMPKINS  BALTIMORE  Conventional  24 inch bins  HOWDEN TYPE   \n",
      "3       PUMPKINS  BALTIMORE  Conventional  24 inch bins  HOWDEN TYPE   \n",
      "4       PUMPKINS  BALTIMORE  Conventional  24 inch bins  HOWDEN TYPE   \n",
      "5       PUMPKINS  BALTIMORE  Conventional  24 inch bins  HOWDEN TYPE   \n",
      "6       PUMPKINS  BALTIMORE  Conventional  36 inch bins  HOWDEN TYPE   \n",
      "\n",
      "         Date  Low Price  High Price  Mostly Low  Mostly High    Origin Repack  \n",
      "2  09/24/2016        160       160.0         160        160.0  DELAWARE      N  \n",
      "3  09/24/2016        160       160.0         160        160.0  VIRGINIA      N  \n",
      "4  11/05/2016         90       100.0          90        100.0  MARYLAND      N  \n",
      "5  11/12/2016         90       100.0          90        100.0  MARYLAND      N  \n",
      "6  09/24/2016        160       170.0         160        170.0  MARYLAND      N  \n"
     ]
    }
   ],
   "source": [
    "#check the shape of the new dataframe, and the columns\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8590082f",
   "metadata": {},
   "source": [
    "## Answer Some Questions\n",
    "\n",
    "Use `groupby()` and `agg()` to answer the following two questions:\n",
    "\n",
    "1. What is the mean low and high prices for each type of unit of sale in the Northeast region? In the last lesson, we learned that a unit of sale could be something like a bin or individually. \n",
    "2. What is the average number of pumpkins for each variety that came into terminal markets for the year by region? Pumpkin varieties include Howden and Fairytale pumpkins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c839639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Commodity Name  City Name          Type       Package      Variety  \\\n",
      "2       PUMPKINS  BALTIMORE  Conventional  24 inch bins  HOWDEN TYPE   \n",
      "3       PUMPKINS  BALTIMORE  Conventional  24 inch bins  HOWDEN TYPE   \n",
      "4       PUMPKINS  BALTIMORE  Conventional  24 inch bins  HOWDEN TYPE   \n",
      "5       PUMPKINS  BALTIMORE  Conventional  24 inch bins  HOWDEN TYPE   \n",
      "6       PUMPKINS  BALTIMORE  Conventional  36 inch bins  HOWDEN TYPE   \n",
      "\n",
      "         Date  Low Price  High Price  Mostly Low  Mostly High    Origin Repack  \n",
      "2  09/24/2016        160       160.0         160        160.0  DELAWARE      N  \n",
      "3  09/24/2016        160       160.0         160        160.0  VIRGINIA      N  \n",
      "4  11/05/2016         90       100.0          90        100.0  MARYLAND      N  \n",
      "5  11/12/2016         90       100.0          90        100.0  MARYLAND      N  \n",
      "6  09/24/2016        160       170.0         160        170.0  MARYLAND      N  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low Price</th>\n",
       "      <th>High Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>134.328125</td>\n",
       "      <td>150.568576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Low Price  High Price\n",
       "mean  134.328125  150.568576"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your code here to find the mean low and high prices in the Northeast region for each type of unit of sale.\n",
    "gb_dftype=df.groupby('Type')\n",
    "print(gb_dftype.head())\n",
    "# agg_func_list = ['mean', 'min', 'max']\n",
    "# agg_gb_dftype=gb_dftype.agg(agg_func_list)\n",
    "# agg_gb_dftype\n",
    "agg_func_dict={\"Low Price\":[\"mean\"],\"High Price\":[\"mean\"]}\n",
    "agg_gb_dftype=df.agg(agg_func_dict)\n",
    "agg_gb_dftype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4b23352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here to find the average number of pumpkins coming into terminal markets of each variety.\n",
    "gb_dfvariety=df.groupby('Variety')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5cff4",
   "metadata": {},
   "source": [
    "## Bonus Mission\n",
    "\n",
    "Try answering the same questions for the Midwest (Chicago, Detroit, and St. Louis) or the Southeast (Atlanta, Columbia, and Miami) regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d22b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the bonus mission if you have time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dbc152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
